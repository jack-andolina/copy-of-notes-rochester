# Readme for the BLW Combined Database

## Why?

Before getting into the details of the database, this section tries to explain why we built the database in the first place.

Let's start with an example of the problem the database is trying to solve.  Here's one of the Bright Line Watch survey questions:

> How well does the following statement describe the United States as of today? Politicians who lose free and fair elections will concede defeat.

Like many of BLW's questions, this one is asked in multiple waves, in both surveys of experts and surveys of the general public.  So we can compare responses to this question between experts and the general public, between members of the public who differ in any of a whole variety of characteristics like partisanship, and within these groups over time.

Suppose we want to do that.  More specifically, suppose we'd like to see how responses to this question before January of 2021 differ from those after January 2021, and we'd like to see whether those over-time differences vary by partisanship among members of the public.  To do this, we're going to need to get the data from the Bright Line Watch surveys that include this question.  With this in mind, take a look at BLW's data page here: https://brightlinewatch.org/survey-data-and-replication-material/.  Notice that there is a separate datafile for each individual wave of the BLW surveys.  In fact, for each wave there are in **two** datafiles -- one from the expert survey and one from the survey of the general public.  So, in order to examine how responses to that question change over time, we're going to have to collect responses from multiple datafiles.  This is of course do-able (the BLW PIs and RAs do it all the time to generate graphics for BLW's reports!), but it's difficult, especially for a person that doesn't have extensive knowledge of the BLW surveys and how responses to all the survey questions are encoded in the raw data generated by each survey.  To give you a sense of the problems you have to solve to merge the data across surveys, here's a table showing the name of the variable in which responses to this question are stored in each datafile from waves 12 through 17:

| wave | population | variable name |
|:--|:--|:--|
| 12 | experts | Q2.6_30 |
| 12 | public  | statements_30 |
| 13 | experts | Q2.6_30 |
| 13 | public  | statements_30 |
| 14 | experts | Q2.6_30 |
| 14 | public  | statements_US_7 |
| 15 | experts | Q2.6_30 |
| 15 | public  | statements_US_7 |
| 16 | experts | Q2.6_30 |
| 16 | public  | statements_US_7 |
| 17 | experts | Q2.6_30 |
| 17 | public  | statements_US_7 |

How would you go about figuring out the name of the variable in each separate datafile storing responses to the particular question you're interested in?  How would you go about making sure the responses are encoded in that variable in a way that is consistent from one wave to another and across populations?  Again, all of that is do-able, but difficult.

That is the problem the BLW Combined Database is trying to solve.  It aims to provide a single source in which one can relatively easily identify and retrieve responses to *all* the survey question asked in *all* the BLW surveys.  Moreover, it aims to allow users to access arbitrary subsets of the data, selecting responses from specific surveys, population samples and subsets of population samples.


## How the database is organized

The BLW Combined Database is a relational database.  This means that it contains multiple tables, each of which stores a particular feature of the BLW data, along with links that connect related rows across tables.  More specifically, the database is implemented using the relational database engine [PostgreSQL](https://www.postgresql.org/).  Thus updating and querying the database are done via [PostgreSQL's dialect of the SQL language](https://www.postgresql.org/docs/16/sql.html).

The section gives an conceptual introduction to the database that does not assume any knowledge of SQL or relational databases more generally.  For the technical details, see [Reference -- DB tables with their SQL definitions](#reference----db-tables-with-their-sql-definitions).


We introduce the tables in the database under three conceptual categories:  **survey questions**, **survey responses**, and **documentation**.

### Survey Questions


The core concept motivating the organization of the database is a *survey question* -- i.e. a question or prompt posed to respondents in a BLW survey.   The database is meant, above all else, to store the definitive list of all unique survey questions asked in the union of all the BLW surveys, along with the responses to those questions by the respondents who responded to the surveys including those questions.  There are three tables in the database that store the BLW survey questions and information about them: the **variables table**, the **batteries table** and the **battery groups table**.

The **variables table** contains the definitive list of unique survey questions stored in the database.   For instance, here are a few rows from the **variables table** featuring questions about respondents' confidence in the 2020 election:   

|variable_name|question_text|description|quirks|battery_name|type|
|---|---|---|---|---|---|
|electconf_able_retrospective2020|How confident are you that people who are legally entitled to vote and sought to do so were able to successfully cast a ballot in the election this November?|Confidence that everyone who was legally entitled to vote was able to do so in the November 2020 elections.|NULL|election confidence and legitimacy|integer|
|electconf_county_retrospective2020|How confident are you that votes in your county were counted as voters intended?|Confidence that votes in respondent's county were counted as voters intended.|NULL|election confidence and legitimacy|integer|
|electconf_nation_retrospective2020|How confident are you that votes nationwide were counted as voters intended?|Confidence that votes nationwide were counted as voters intended.|NULL|election confidence and legitimacy|integer|
|electconf_state_retrospective2020|How confident are you that votes in your state were counted as voters intended?|Confidence that voters in respondent's state were counted as voters intended.|NULL|election confidence and legitimacy|integer|

As may be apparent from this example, the **variables table** has one row for each unique survey question in the BLW surveys.  Each row specifies a unique variable name for the question (in the `variable_name` column), the text of the question as presented to respondents (`question_text` column), a description (`description` column) of the question, and a `quirks` column for recording irregular features of questions that should be accounted for in analysis.  The `type` column records the SQL type in which responses to the question are stored (in another table in the database that you will learn about soon enough!).  The `battery_name` column stores the name of the battery to which the question belongs, which leads us to the next table in our database...

So far, the BLW database holds over 1800 unique survey questions.  These represent all the questions asked only through Wave 17 of the BLW surveys.  So the number of survey questions in database will get even larger as we add additional surveys.  Because there are so many questions in the BLW surveys, users of the database who aren't already deeply familiar with the BLW project will need some help browsing the questions to find what they're looking for.  For this purpose, the database organizes questions into *question batteries* and then groups those batteries into *battery groups*.

The **batteries table** holds the list of all question batteries in the DB and the **battery groups** table holds the list of all battery groups.  For instance, all of the questions you saw above about confidence in the 2020 election belong to the "election confidence and legitimacy" battery, which is stored in this row of the **batteries table**:

|battery_name|description|question_prefix|description_prefix|battery_group|battery_id|
|---|-----|---|---|---|---|
|election confidence and legitimacy|Questions in this battery assess public confidence in the major U.S. elections that have taken place during the Bright Line Watch surveys, including the 2020, 2022, and 2024 elections.  Questions are asked both prospectively (for instance, asking respondents whether they would view a given prospective outcome as legitimate) and retrospectively (asking respondents whether they view outcomes that have already occurred as legitimate).  Question probe respondents' views of election integrity and at the local, state and national level.   Combined with questions from the demographics battery and the partisanship and ideology battery, these items give a thorough picture of the nature and extent of polarization in election confidence since the Trump's challenge to the 2020 election result.|NULL|NULL|election confidence|18|

As you can see, the **batteries table** gives a detailed description, in the `description` field of each question battery.  It also includes a `question prefix` and `description prefix` field, which contain any text that prefixes every question and description, respectively, of every question in the battery.  It also assigns a unique id number to each battery (in the `battery_id` column), which makes it easier to write code that interfaces with the database.  Finally, it identifies which battery group the battery belongs to using the `battery_group` field.

All the battery groups are listed in the **battery_groups table**.  There are 56 batteries in the database so far.  That's a pretty big number.  So to make things even easier to browse for a user not familiar with the project, the batteries are organized into (only) 14 battery groups, listed in the **battery_groups table** as follows:

|group_name|group_description|parent_battery_group|
|---|---|---|
|assessing constitutional hardball|pending|expert assessments|
|assessing events|pending|expert assessments|
|assessing institutional changes and reforms|pending|expert assessments|
|assessing the normality and importance of events|pending|assessing events|
|democratic norms|These batteries measure the public's support for democratic norms and expert and public views about the behaviors and practices that reinforce or undermine democracy.|NULL|
|democratic performance|Batteries in this group ask experts and members of the public to rate the quality of democracy at the state and national level on a variety of dimensions.|NULL|
|election confidence|Batteries in this group measure the public's confidence in U.S. elections at the local| state and national level.|NULL|
|event predictions|pending|expert assessments|
|expert assessments|These are the core batteries measuring experts' judgements about the state of democracy in the United States and around the world.|NULL|
|expert covariates|Use these batteries to compare the distribution of expert judgements by occupation| field of study and location of academic institution.|NULL|
|prioritizing problems for american democracy|pending|expert assessments|
|public covariates|Use these batteries to compare the distribution of responses between different groups of members of the public.|NULL|
|response metadata|pending|NULL|
|survey experiments|These batteries use experimental methods to explore the causes of public support for democracy and democratic practices.|NULL|

As you can see, in addition to a `group_name`, each battery group has a `group_description` and a `parent_battery_group`.  The parent battery group allows us to organize the groups hierchically to make browsing easier for users.  For instance, the group "assessing the normality and importance of events" is a sub-group of the "assessing events" group.

### Survey Responses

Three tables store responses to survey questions and information about those responses: the **responses table**, the **variables-values-labels table**, and the **surveys table**.

To understand the contents of the **responses table**, recall again that the database is organized around the complete list of unique *survey questions* contained in the combination of all the BLW surveys.  Thus the data in the responses table is organized by these questions.  More specifically, the responses table stores the response to each survey question from each survey respondent who participated in a survey that included that question, with one response by one respondent to one question in each row of the table.

For instance, here is another of the many BLW survey questions, as stored in the variables table:

|variable_name|question_text|description|quirks|battery_name|type|
|---|---|---|---|---|---|
|imp_gov_stats|Government statistics and data are produced by experts who are not influenced by political considerations.|Government statistics and data are produced by experts who are not influenced by political considerations.|NULL|democratic characteristics: importance|integer|

As you can see, the variable name "imp_gov_stats" is assigned to this question.   Up through Wave 17, "imp_gov_stats" has appeared in three BLW surveys: The Wave 11 survey of experts, the Wave 14 survey of experts, and Wave 14 survey of the general public.   A total of 4024 respondents participated in one or more of these three surveys.  Thus there are 4024 rows in the responses table recording responses to "imp_gov_stats".  Here is a random sample of 10 of those responses:

|identifier|survey_id|variable_name|response|
|---|---|---|---|
|BLW0200052|43|imp_gov_stats|3.0|
|0000041478334|49|imp_gov_stats|nan|
|0000132228166|49|imp_gov_stats|4.0|
|BLW0008268|43|imp_gov_stats|4.0|
|BLW0004319|43|imp_gov_stats|nan|
|0000068002897|49|imp_gov_stats|nan|
|0000185005924|49|imp_gov_stats|nan|
|0000036597037|49|imp_gov_stats|4.0|
|0000149999413|49|imp_gov_stats|nan|
|0000213254842|49|imp_gov_stats|nan|

As you can see, the responses table has the following columns:

+ `identifier`  This is a string that uniquely identifies the respondent who gave the response.  Notice in the example above that some of the identifiers have the form BLWXXXXXXX" and other are 14-digit strings of numbers, left-padded with 0.  The former are the identifiers for expert respondents, while the latter are identifiers for respondents from the general public.
+ `survey_id`  This is an integer that uniquely identifies the survey that generated the response.  For instance, survey 43 is the Wave 11 survey of experts.  More information about each survey is stored in the **surveys table**, which you'll learn about shortly.
+ `variable_name`  You already know that this is the string that uniquely identifies the survey question that generated the response, and that you can use it to look up details about the survey question (such as the text of the question) in the **variables table**.
+ `response`  This is the response given by the respondent.  Notice that in the example above, there are a number of responses marked 'nan'.  In many BLW surveys, some questions are only presented to a random subsample of respondents, and imp_gov_stats happens to be one of those questions.  "nan" in the `response` column for this question, then, means that the respondent participated in the survey in which imp_gov_stats was included, but was randomly chosen to not see the imp_gov_stats question.  Also notice that the non-'nan' responses are numbers.  What do these numbers mean?  That brings us to the next table!

Respondents presented with the "imp_gov_stats" question are asked to choose one of the following responses:

+ "not relevant.  this has no impact on democracy"
+ "beneficial.  this enhances democracy but is not required for democracy"
+ "important.  if this is absent, democracy is compromised"
+ "essential. a country cannot be considered a democracy without this"

Most questions in the BLW surveys are like this.  Specifically, they ask respondents to choose one of set of alternative pre-determined text responses.  In order reduce the amount of space the database takes up on disk, we do not store the full text of a respondent's chosen response to a question like this in the responses table.  Instead, we assign a numeric code to each response, and store the code for each respondent's response in the `responses` table.  So, for instance, when you see this in the responses table...

|identifier|survey_id|variable_name|response|
|---|---|---|---|
|BLW0200052|43|imp_gov_stats|3.0|
|0000132228166|49|imp_gov_stats|4.0|

...You know that respondent BLW0200052 respondent to imp_gov_stats with the response coded 3.0 and respondent 000132228166 with the response coded 4.0.

So, how do you de-code those values and recover the actual text of the responses?  The information needed is stored in the **variables-values-labels table**.  Here, for instance, are the rows from the variables-values-labels table needed for de-coding responses to imp_gov_stats:

|variable_name|value|label|
|---|---|---|
|imp_gov_stats|1|not relevant. this has no impact on democracy|
|imp_gov_stats|2|beneficial. this enhances democracy but is not required for democracy|
|imp_gov_stats|3|important. if this is absent| democracy is compromised|
|imp_gov_stats|4|essential. a country cannot be considered a democracy without this|

As you can see, the variables-values-labels table has a `variable_name` column that uniquely identifies the survey question, a `value` column that identifies the numeric code assigned to a response, and a `label` column that records the full text of the response corresponding to the value.

The third table storing survey responses and information about those responses is the **surveys table**.  Look again at the 10 randomly-selected rows of the responses table holding responses to imp_gov_stats...

|identifier|survey_id|variable_name|response|
|---|---|---|---|
|BLW0200052|43|imp_gov_stats|3.0|
|0000041478334|49|imp_gov_stats|nan|
|0000132228166|49|imp_gov_stats|4.0|
|BLW0008268|43|imp_gov_stats|4.0|
|BLW0004319|43|imp_gov_stats|nan|
|0000068002897|49|imp_gov_stats|nan|
|0000185005924|49|imp_gov_stats|nan|
|0000036597037|49|imp_gov_stats|4.0|
|0000149999413|49|imp_gov_stats|nan|
|0000213254842|49|imp_gov_stats|nan|

...and recall that we use an integer identifier to indicate which survey the response in any given row of the responses table comes from.  So, which BLW survey has a given identifier?  That information is in the **surveys table**.  Notice that the randomly selected responses above come from the surveys with identifiers 43 and 49.  Here are the rows corresponding to those surveys in the surveys table: 

|survey_id|wave|population|
|---|---|---|
|43|11|experts|
|49|14|public|

As you can see, the survey with id number 43 is the wave 11 expert survey, and the survey with id number 49 is the wave 14 public survey.


One more note about the `responses` table before we move on the remaining tables in the database.  If you have any prior experience with survey data, you're probably familiar with datasets stored in a "rectangular" format.  In this format, survey responses are stored in a table in which there is one row for each unique respondent, and one column for each survey question, with a variable name in the header uniquely identifying each survey question.  You may have noticed that this is NOT the format in which data is stored in this database!  Instead, the responses table is in a "long-and-narrow" format, in which the responses given by each survey respondent to the multiple questions in a survey are spread across multiple rows, one row for each survey question in the survey in which the respondent participated.

Why is the database organized in this very unfamiliar (for most social scientists, at least) format?  First of all, there are 1800+ survey items (with more coming soon) stored in this database.  So a rectangular version of the data would be too wide to be visually browsed in the way that rectangular datasets are designed to be.  Second (and more importantly), the long-and-narrow format saves a huge amount of space on disk relative to the rectangular format.  BLW has now fielded over 40 surveys.  Each survey has anywhere from about 1k to about 2.5k respondents.  That means that a rectangular form of the data would have at least 40*1k = 40,000 rows.  That's fine in and of itself.  But it's not fine when considered in light of the fact that the vast majority of the 1800+ questions in the BLW surveys are only included in a handful of BLW's 40+ surveys.  So, if put into a rectangular format, the vast majority of cells in the table would be blank, because most respondents would not have participated in the surveys in which the typical survey question was included, and all those blank responses would take up space on disk.  The long-and-narrow format gets rid of all these blank cells, since there is a row for a response by a respondent to a given survey question *only* when that respondent participated in a survey that included that question.


### Documentation

The final tables in the database to describe are those that store information needed for documenting the process through which the raw data from the surveys has been transformed to populate the database.  Populating the database with survey questions and responses requires many judgement calls, and writing and running a lot of error-prone data-handling code.  So we want to make sure that all of the steps taken in populating the database are documented so that they can be examined and modified.  That's what the tables in this section make possible.

The documentation tables are the **variable-name-map table** and the **surveys table**.

To understand the **variable-name-map table** consider once again the survey question...

> How well does the following statement describe the United States as of today? Politicians who lose free and fair elections will concede defeat.

The database assigns the variable name "perf_concede_defeat" to this question.

What if we need to make sure that the responses stored in the database under the variable name "imp_concede_defeat" correctly correspond to the responses in the original datafiles produced by the surveys in which this question appeared?  That would, of course, require identifying the variable name corresponding to this question in each of the original datafiles.  And that is what the variable-name-map table does.  Here are a few rows from that table:

|variable_name|survey_id|survey_specific_name|
|---|---|---|
|perf_concede_defeat|44|Q2.6_30|
|perf_concede_defeat|45|statements_30|
|perf_concede_defeat|46|Q2.6_30|
|perf_concede_defeat|47|statements_30|
|perf_concede_defeat|48|Q2.6_30|
|perf_concede_defeat|49|statements_US_7|
|perf_concede_defeat|50|Q2.6_30|
|perf_concede_defeat|51|statements_US_7|
|perf_concede_defeat|52|Q2.6_30|
|perf_concede_defeat|53|statements_US_7|
|perf_concede_defeat|54|Q2.6_30|
|perf_concede_defeat|55|statments_US_7|

The column "survey_specific_name" in the variable-name-map table stores the name of the variable in the raw datafile from the survey referenced in the survey_id column for the question referenced in the variable_name column.

The last table we need to describe is the **surveys table**.   You've already seen that the survey table is used to link each survey's id number to its wave and population.  The survey's table also holds critical information for documenting the database.  As we mentioned at the outset, the original BLW data is stored in many separate datafiles, one datafile for each distinct survey.  Thus constructing the database amounts to a process of taking each of these many datafiles and merging them together.  In addition to the "wave" and "populations" column, the surveys table contains the following columns for documenting the database:

+ **raw_data_file**: This column holds the raw bytes of the SPSS .sav file containing the raw data used to populate the database for the survey with the survey id number in that row.
+ **raw_data_file_type**: So far, all raw datafiles used to construct the database are SPSS .sav files, and for those surveys this column holds the string "sav".  If raw datafiles of a different format (e.g. csv, dta) are used in for future surveys, this column will record the types.
+ **raw_data_row_dropper**: Many of the raw datafiles include rows recording responses that should not be used in any analysis.   Some of these responses are test runs instead of genuine responses.  Others are responses interrupted by a network error.  For each survey in the surveys table, the raw_data_row_dropper holds the Python code used to drop rows from the raw datafile to exclude data from those rows in the database.  This code is stored in binary format generated by the [python pickle library](https://docs.python.org/3/library/pickle.html).
+ **raw_data_transformer**:  For some of the BLW surveys, the raw datafile is NOT in a strictly rectangular format.  More precisely, in some files responses to some questions are disaggregated across multiple columns of the datafile.  In these cases, these multiple columns need to be aggregated into a single column before they can be added to the database, so that the name of the (newly created) single column can be used in the **variable_name_map_table**.  For surveys where such a transformation was required, the raw_data_transformer column holds python code in binary format (generated by python pickle) used to execute the transformation.



## How to Add Surveys to the Database

Adding a survey to the database is a process that requires some judgement calls, along with a lot of fine-grained, detail-oriented, and thus error-prone data entry.  As such, we do it in a way that tries to make the process as transparent as possible -- so that everyone who works on the project can see and review all the judgement calls and error-prone minutiae *before* making any actual modification to the database.

The process entails first making changes to a *model* of the database, which is rendered in a language called JSON.   Then, once the changes to the JSON model look good, running code that modifies the database to bring it into line with the model.  JSON is purely text-based way to represent data structures, so its relatively easy for a normal human to manipulate and understand.

The JSON model you'll modify to add a survey, along with the code that can modify the database to reflect changes to the model lives in this github repo:

https://github.com/stuvjordan-uroc/blw-combined-json

Within that repo, the actual JSON model of the database is in the `db_json` folder, which contains three files:

+ `batteries.json`
+ `battery_groups.json`
+ `surveys.json`

Rather than walk through these files in the abstract, we'll show how to use them by illustrating the process of adding the data from two surveys -- the Wave 18 expert survey, and the Wave 18 public survey.  As of the time of this writing, the JSON model and the database only represent the BLW surveys running through Wave 17.  So, what we show here should apply to adding the surveys from whatever wave is subsequent to the last wave added to the database.

One more note before we get started:  Because you'll be working with JSON files, you'll be able to work much more efficiently if you use a text editor that has lots of features for editing and browsing JSON.  For this purpose, we highly recommend installing [VSCode](https://code.visualstudio.com/).

### Adding the Wave 18 Expert Survey

### Step 1: Clone the github rep

```
git clone https://github.com/stuvjordan-uroc/blw-combined-json
cd blw-combined-json
```

#### Step 2: Get the survey instrument and the raw datafile

For Wave 18, the expert survey instrument can be had on the BLW website at

https://brightlinewatch.org/wp-content/uploads/2022/12/blw_w18_expert_flow.pdf

The survey data can be found in the BLW Dropbox at

`Survey data/Wave 18/data/raw/BLW+wave+18+experts_December+1,+2022_10.35.sav`

Notice that we're getting the _raw_ datafile -- not any version that has been cleaned.  This allows us to document _all_ the modifications of the raw data (including any data cleaning) in the database.

Once you have the raw datafile, you should rename it following the conventions used in the repo,  then put it into the `raw_data` folder in your local copy of the repo.  The file naming conventions will hopefully be apparent if you take a look at the `raw_data` folder.  For instance, the Wave 18 expert survey raw datafile `w018_experts_standard.sav`.

### Step 3: Inventory the survey questions

You now need to get a handle on the questions that are actually in the survey.  Do this step outside of the repo.  The best approach is probably to work with a spreadsheet (e.g. in excel or google sheets).

Read through the survey instrument, making a list of all of the survey questions in the instrument as you go.  You don't need to record their text exactly at this point.  You just need to make sure that in your list, you get every question in the survey down in a way that allows you to clearly match what you've written to each actual survey question.

For instance, working an excel spreadsheet to keep track of things, you might start with a list of the survey questions from the Wave 18 expert survey something like this:

![](img/expert_18_step4_01.png)

### Step 4:  Determine which survey questions are already captured in the database

Recall that some survey questions are repeated across multiple BLW surveys, while others show up only in one survey.  So, when you go to add a new survey to the database, any given question in that survey might be one that has appeared in a previous survey, or might be one that is making its debut in the survey you're working with.  Further, you're adding surveys to the database sequentially.  So _if_ a question in the survey you're adding to the database _has_ appeared in a previous survey, there will be an entry in the database corresponding to that question.

How do you know whether or not a survey question has already appeared in a previous BLW survey?  In some cases, just being familiar with BLW's work will be enough.  For instance, every BLW report discusses the responses to the questions in the "democratic performance" battery that begin "How well do the following statements describe the United States as of today?"   So when you see those questions in a survey you're adding to the database, you might recognize them.

But when you first start working on this project, you will definitely see survey questions you don't recognize, so you'll need to check.

To do so, go into your local copy the repo you cloned in the previous step.  In whatever text editor you're using (again, we recommend [VSCode](https://code.visualstudio.com/)), open the JSON file `batteries.json`, which is in the `db_json` folder.

`batteries.json` represents all the question batteries in the database, up through the last survey added to the database.  It does so via a dictionary in which each key is the name of a battery, and each value is a dictionary with key-value pairs recording all kinds of information about the battery and the variables that belong to the battery.

For instance, here's the entry in `batteries.json` for the _maricopa county audit experiment_ battery, which was a survey experiment run in one of BLW's public surveys:
```
"maricopa_county_audit_experiment": {
    "battery_group": "survey_experiments",
    "battery_name": "maricopa county audit experiment",
    "description": "pending",
    "description_prefix": null,
    "question_prefix": null,
    "variables": {
      "mc_audit_biden_winner": {
        "description": "Whether respondent considers Joe biden the rightful winnor or not the rightful winner of the vote in Maricopa County.",
        "question_text": "Do you consider Joe Biden to be the rightful winner of the vote in Maricopa County or not the rightful winner?",
        "quirks": null,
        "type": "integer",
        "variable_name": "mc_audit_biden_winner",
        "vvl_map": {
          "1": "definitely the rightful winner",
          "2": "probably the rightful winner",
          "3": "probably not the rightful winner",
          "4": "definitely not the rightful winner",
          "998": "skipped",
          "999": "not asked"
        }
      },
      "mc_audit_count_correct": {
        "description": "Confidence that the official count of votes for president in Maricopa County was correct.",
        "question_text": "How confident are you that the official count of votes for president in Maricopa County was correct?",
        "quirks": null,
        "type": "integer",
        "variable_name": "mc_audit_count_correct",
        "vvl_map": {
          "1": "very confident",
          "2": "somewhat confident",
          "3": "not too confident",
          "4": "not at all confident",
          "998": "skipped",
          "999": "not asked"
        }
      },
      "mc_audit_tx": {
        "description": "Which treatment arm of the Maricopa County Audit Experiment the respondent was exposed to.",
        "question_text": "no question",
        "quirks": null,
        "type": "integer",
        "variable_name": "mc_audit_tx",
        "vvl_map": {
          "1": "no text",
          "2": "official audit",
          "3": "crazy audit",
          "998": "skipped",
          "999": "not asked"
        }
      }
    }
  }
```

There is a lot going on here.  But for now, just focus on one thing:  The _variables_ entry.  Each battery entry in `batteries.json` has a _variables_ entry.  And the _variables_ entry for each battery has one entry for each variable that belongs to that battery.  For instance, the _maricopa county audit experiment battery_ has three variables -- mc_audit_biden_winner, mc_audit_count_correct, and mc_audit_tx.

Now recall a fact about the database:  Every unique question in the BLW surveys is assigned to a unique variable in the database, and every variable in the database is assigned to a unique battery.  So, if a question in the survey your adding to the database _has_ appeared in another BLW survey that has already been added to the database, then that question will have been assigned to a variable that appears somewhere in `batteries.json`.

So you can search (typically via CTRL-F, depending on your text editor) in `batteries.json` to see if you can find a variable that matches any given question in the survey you're adding.  What text exactly should you search for?  Take a look at the entry from `batteries.json` for the variable mc_audit_biden_winner:
```
"mc_audit_biden_winner": {
        "description": "Whether respondent considers Joe biden the rightful winnor or not the rightful winner of the vote in Maricopa County.",
        "question_text": "Do you consider Joe Biden to be the rightful winner of the vote in Maricopa County or not the rightful winner?",
        "quirks": null,
        "type": "integer",
        "variable_name": "mc_audit_biden_winner",
        "vvl_map": {
          "1": "definitely the rightful winner",
          "2": "probably the rightful winner",
          "3": "probably not the rightful winner",
          "4": "definitely not the rightful winner",
          "998": "skipped",
          "999": "not asked"
        }
      }
```
Notice that it, like every variable entry in `batteries.json`, it includes the full text of the survey question corresponding to that variable, along with a textual description of the question.  So in general, if a question in a survey you're working with has appeared in a previous survey that has already been added to the database, you can find it by searching in `batteries.json` for text that matches the question.

For each variable in the survey you're working with, search to see whether it has a matching question in `batteries.json`.  If you find a match, record the viarable name of the matching question in your spreadsheet.  If not, indicate that there is no match.  If you find something that seems like an ambiguous or uncertain match, ask your supervisor for help.

Here, for instance, is what part of your spreadsheet might look like if you're working your way through the Wave 18 expert survey:

![](img/expert_18_step4_02.png)

As you can see, we've got a column indicating whether each question corresponds to a variable already in the DB.  The selection of perf questions we've included _are_ already in the DB, and we've recorded the name of the variable in the DB for each of those questions.  On the other hand, we've shown entries for two qustions from the Wave 18 expert survey that did not appear in any surveys already added to the DB.  We've marked those questions 'NEW QUESTION'.  Finally notice that we've put a ??? next to the consent question.  From a search of `batteries.json`, there doesn't appear to be a variable recording answers to the informed consent question that appears at the outset of the Wave 18 expert survey.  Yet surely such a consent question has appeared in all the previous surveys?  For this reason, you might put '???' in your spreadsheet next to that question.  This is an example of something you might follow up with your supervisor about.

### Step 5: Assign new questions to batteries

Recall once again that every survey question in the database is assigned to a variable in the database, and every variable belongs to a battery.  For instance, the question "Do you consider Joe Biden to be the rightful winner of the vote in Maricopa County or not the rightful winner?" is assigned to the variable mc_audit_biden_winner, which belongs to the maricopa_county_audit_experiment battery.

So, if having completed Step 4 you've identified survey questions in the survey you're adding to the database that have not appeared in previous surveys, you'll need to create a variable for each of those new questions, and assign each of those variables to a battery.  For a number reasons, it's better to pick the batteries before assigning variables.

When you assign a new question to a battery, the first thing to consider is whether there is already a battery in the database to which a question should be assigned.  For instance, the Wave 18 expert survey includes a series of questions in which respondents are asked to rate the extent to which each of set of events is "normal" or "abnormal".  One of these events is:

> After losing the gubernatorial election in Arizona, Republican nominee Kari Lake refuses
to concede.

This particular question about the behavior of the Arizona demagogue Kari Lake was new in the Wave 18 expert survey.  But the _battery_ -- in which respondents are presented with a series of recent events and asked to rate the normal-ness or abnormal-ness of each event -- had been used in several waves prior to 18.  So you would need to create a new _variable_ in the database corresponding to this question, but you'd want to assign that variable to the _existing_ battery of normal/abnormal questions in the database.

What about the case of a new question that seems to be part of a battery of questions that has not appeared in any previous survey? In such a case, please ask your supervisor to create a battery for the question.  The decision about how to structure, name, and describe a new battery is best made by someone with relatively extensive knowledge of the BLW project.

Anyway, for all new survey questions in the survey you're working with that should be assigned to existing batteries, find the name of the battery in `batteries.json`.  Then record the battery names in your spreadsheet.  It should look something like this:

![](img/expert_18_step5_01.png)







### Step 5: Assign variable names to new questions

Recall once again that every survey question in the database is assigned to a variable in the database.  For instance, the question "Do you consider Joe Biden to be the rightful winner of the vote in Maricopa County or not the rightful winner?" is assigned to the variable mc_audit_biden_winner.

This means that when you add a survey to the database, any questions in that survey that have not appeared in another survey already added to the database will need to be assigned a variable name in the database.  So, having completed Step 4, you'll need to create new variable names to associate with each question in the survey you're working with that you've determined has not appeared in another BLW survey that has already been added to the database.

How should you decide on the variable name for any such question?  First look in the raw datafile to see if you can identify the variable name used for your question in the datafile.  `.sav` files have built-in metadata tables that can be helpful with this.  If you like to work with datafiles in R, you can read any metadata attached to a `.sav` file using the [haven](https://haven.tidyverse.org/) package.  Pandas can also read `.sav` files and makes the metadata tables readily accessible.

Sometimes the variable names used in the raw datafiles are great as-is, and sometimes they totally suck.  In general, we want to use variable names that are somewhat indicative of the content of the question.  


## Reference -- DB tables with their SQL definitions

### Variables Table

```
CREATE TABLE variables
(
    variable_name text NOT NULL,
    question_text text  NOT NULL,
    description text  NOT NULL,
    quirks text,
    battery_name text  NOT NULL,
    type datatype NOT NULL,
    CONSTRAINT variables_pkey PRIMARY KEY (variable_name),
    CONSTRAINT variables_battery_name_fkey FOREIGN KEY (battery_name)
        REFERENCES batteries (battery_name) MATCH SIMPLE
        ON UPDATE NO ACTION
        ON DELETE NO ACTION
)
```

### Batteries Table

```
CREATE TABLE batteries
(
    battery_name text NOT NULL,
    description text NOT NULL,
    question_prefix text,
    description_prefix text,
    battery_group text,
    battery_id integer NOT NULL GENERATED ALWAYS AS IDENTITY ( INCREMENT 1 START 1 MINVALUE 1 MAXVALUE 2147483647 CACHE 1 ),
    CONSTRAINT batteries_pkey PRIMARY KEY (battery_name),
    CONSTRAINT batteries_battery_group_fkey FOREIGN KEY (battery_group)
        REFERENCES public.battery_groups (group_name) MATCH SIMPLE
        ON UPDATE CASCADE
        ON DELETE NO ACTION
)
```

### Battery Groups Table


```
CREATE TABLE battery_groups
(
    group_name text NOT NULL,
    group_description text NOT NULL,
    parent_battery_group text ,
    group_order integer,
    CONSTRAINT battery_groups_pkey PRIMARY KEY (group_name),
    CONSTRAINT battery_groups_parent_battery_group_fkey FOREIGN KEY (parent_battery_group)
        REFERENCES public.battery_groups (group_name) MATCH SIMPLE
        ON UPDATE CASCADE
        ON DELETE NO ACTION
)
```

### Responses Table

```
CREATE TABLE responses
(
    identifier text  NOT NULL,
    survey_id integer NOT NULL,
    variable_name text  NOT NULL,
    response text  NOT NULL,
    CONSTRAINT responses_pkey PRIMARY KEY (identifier, survey_id, variable_name),
    CONSTRAINT responses_survey_id_fkey FOREIGN KEY (survey_id)
        REFERENCES surveys (survey_id) MATCH SIMPLE
        ON UPDATE NO ACTION
        ON DELETE NO ACTION,
    CONSTRAINT responses_variable_name_fkey FOREIGN KEY (variable_name)
        REFERENCES variables (variable_name) MATCH SIMPLE
        ON UPDATE NO ACTION
        ON DELETE NO ACTION
)
```

### Variables-Values-Labels Table


```
CREATE TABLE variables_values_labels
(
    variable_name text  NOT NULL,
    value integer NOT NULL,
    label text  NOT NULL,
    CONSTRAINT variables_values_labels_pkey PRIMARY KEY (variable_name, value, label),
    CONSTRAINT variables_values_labels_variable_name_fkey FOREIGN KEY (variable_name)
        REFERENCES public.variables (variable_name) MATCH SIMPLE
        ON UPDATE NO ACTION
        ON DELETE NO ACTION
)
```


### Surveys Table

```
CREATE TABLE surveys
(
    survey_id integer NOT NULL DEFAULT nextval('surveys_survey_id_seq'::regclass),
    wave integer NOT NULL,
    population text NOT NULL,
    survey_type text NOT NULL,
    raw_data_file bytea,
    raw_data_file_type text ,
    raw_data_transformer text ,
    raw_data_row_dropper text ,
    id_column_name text ,
    month_year text ,
    CONSTRAINT surveys_pkey PRIMARY KEY (survey_id, wave, population, survey_type),
    CONSTRAINT surveys_survey_id_key UNIQUE (survey_id)
)
```


### Variable-Name-Map Table

```

CREATE TABLE IF NOT EXISTS public.variable_name_map
(
    variable_name text NOT NULL,
    survey_id integer NOT NULL,
    survey_specific_name text  NOT NULL,
    CONSTRAINT variable_name_map_pkey PRIMARY KEY (variable_name, survey_id, survey_specific_name),
    CONSTRAINT variable_name_map_survey_id_fkey FOREIGN KEY (survey_id)
        REFERENCES public.surveys (survey_id) MATCH SIMPLE
        ON UPDATE NO ACTION
        ON DELETE NO ACTION,
    CONSTRAINT variable_name_map_variable_name_fkey FOREIGN KEY (variable_name)
        REFERENCES public.variables (variable_name) MATCH SIMPLE
        ON UPDATE NO ACTION
        ON DELETE NO ACTION
)
```
